{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/sberbank-russian-housing-market/data_dictionary.txt\n/kaggle/input/sberbank-russian-housing-market/train.csv.zip\n/kaggle/input/sberbank-russian-housing-market/macro.csv.zip\n/kaggle/input/sberbank-russian-housing-market/test.csv.zip\n/kaggle/input/sberbank-russian-housing-market/sample_submission.csv.zip\n/kaggle/input/cleaned-csv-files/train_cleaned.csv\n/kaggle/input/cleaned-csv-files/test_cleaned.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns',500)","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn import metrics,preprocessing\nimport lightgbm as lgb","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(data):\n    data.loc[data['full_sq'].isnull(),'full_sq']=50\n    data['relative_floor']=data['floor']/data['max_floor'].astype(float)\n    data['room_size']=data['life_sq']/data['num_room'].astype(float)\n    data['month']=data['timestamp'].dt.month.astype(int)\n    data['year']=data['timestamp'].dt.year.astype(int)\n    data['dayOfWeek']=data['timestamp'].dt.dayofweek.astype(int)\n    data['bought_minus_built']=data['timestamp'].dt.year.astype(int)-data['build_year']\n    data['product_type']=data['product_type'].map(lambda x: 1 if x=='OwnerOccupier' else 0)\n    data=data.applymap(lambda x : x if x!='Yes' else 1)\n    data=data.applymap(lambda x : x if x!='No' else 0)\n    return data","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/cleaned-csv-files/train_cleaned.csv',index_col=['id'],parse_dates=['timestamp'])\ntest=pd.read_csv('../input/cleaned-csv-files/test_cleaned.csv',index_col=['id'],parse_dates=['timestamp'])\nprint(train.shape,test.shape)\n","execution_count":6,"outputs":[{"output_type":"stream","text":"(30470, 291) (7662, 290)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.dtypes.value_counts())\nprint(test.dtypes.value_counts())","execution_count":7,"outputs":[{"output_type":"stream","text":"int64             155\nfloat64           120\nobject             15\ndatetime64[ns]      1\ndtype: int64\nint64             157\nfloat64           117\nobject             15\ndatetime64[ns]      1\ndtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=preprocess(train)\ntrain.shape","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(30470, 297)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=preprocess(test)\ntest.shape","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"(7662, 296)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes.value_counts()\ntest.dtypes.value_counts()\n","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"int64             161\nfloat64           120\nobject             14\ndatetime64[ns]      1\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.product_type.value_counts()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"0    19447\n1    11023\nName: product_type, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Price level multipliers here. I've copied it from Andy Harless script:\n#    https://www.kaggle.com/aharless/exercising-the-exorcism\n\nrate_2015_q2 = 1\nrate_2015_q1 = rate_2015_q2 / 0.9932\nrate_2014_q4 = rate_2015_q1 / 1.0112\nrate_2014_q3 = rate_2014_q4 / 1.0169\nrate_2014_q2 = rate_2014_q3 / 1.0086\nrate_2014_q1 = rate_2014_q2 / 1.0126\nrate_2013_q4 = rate_2014_q1 / 0.9902\nrate_2013_q3 = rate_2013_q4 / 1.0041\nrate_2013_q2 = rate_2013_q3 / 1.0044\nrate_2013_q1 = rate_2013_q2 / 1.0104  # This is 1.002 (relative to mult), close to 1:\nrate_2012_q4 = rate_2013_q1 / 0.9832  #     maybe use 2013q1 as a base quarter and get rid of mult?\nrate_2012_q3 = rate_2012_q4 / 1.0277\nrate_2012_q2 = rate_2012_q3 / 1.0279\nrate_2012_q1 = rate_2012_q2 / 1.0279\nrate_2011_q4 = rate_2012_q1 / 1.076\nrate_2011_q3 = rate_2011_q4 / 1.0236\nrate_2011_q2 = rate_2011_q3 / 1\nrate_2011_q1 = rate_2011_q2 / 1.011\n\n\n# train 2015\ntrain['average_q_price'] = 1\n\ntrain_2015_q2_index = train.loc[train['timestamp'].dt.year == 2015].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\ntrain.loc[train_2015_q2_index, 'average_q_price'] = rate_2015_q2\n\ntrain_2015_q1_index = train.loc[train['timestamp'].dt.year == 2015].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\ntrain.loc[train_2015_q1_index, 'average_q_price'] = rate_2015_q1\n\n\n# train 2014\ntrain_2014_q4_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\ntrain.loc[train_2014_q4_index, 'average_q_price'] = rate_2014_q4\n\ntrain_2014_q3_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\ntrain.loc[train_2014_q3_index, 'average_q_price'] = rate_2014_q3\n\ntrain_2014_q2_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\ntrain.loc[train_2014_q2_index, 'average_q_price'] = rate_2014_q2\n\ntrain_2014_q1_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\ntrain.loc[train_2014_q1_index, 'average_q_price'] = rate_2014_q1\n\n\n# train 2013\ntrain_2013_q4_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\ntrain.loc[train_2013_q4_index, 'average_q_price'] = rate_2013_q4\n\ntrain_2013_q3_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\ntrain.loc[train_2013_q3_index, 'average_q_price'] = rate_2013_q3\n\ntrain_2013_q2_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\ntrain.loc[train_2013_q2_index, 'average_q_price'] = rate_2013_q2\n\ntrain_2013_q1_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\ntrain.loc[train_2013_q1_index, 'average_q_price'] = rate_2013_q1\n\n\n# train 2012\ntrain_2012_q4_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\ntrain.loc[train_2012_q4_index, 'average_q_price'] = rate_2012_q4\n\ntrain_2012_q3_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\ntrain.loc[train_2012_q3_index, 'average_q_price'] = rate_2012_q3\n\ntrain_2012_q2_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\ntrain.loc[train_2012_q2_index, 'average_q_price'] = rate_2012_q2\n\ntrain_2012_q1_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\ntrain.loc[train_2012_q1_index, 'average_q_price'] = rate_2012_q1\n\n\n# train 2011\ntrain_2011_q4_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\ntrain.loc[train_2011_q4_index, 'average_q_price'] = rate_2011_q4\n\ntrain_2011_q3_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\ntrain.loc[train_2011_q3_index, 'average_q_price'] = rate_2011_q3\n\ntrain_2011_q2_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\ntrain.loc[train_2011_q2_index, 'average_q_price'] = rate_2011_q2\n\ntrain_2011_q1_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\ntrain.loc[train_2011_q1_index, 'average_q_price'] = rate_2011_q1\n\ntrain['price_doc'] = train['price_doc'] * train['average_q_price']\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nY=train['price_doc']\ntrain=train.drop(['sub_area','ecology','price_doc','average_q_price','timestamp'],axis=1)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test.drop(['sub_area','ecology','timestamp'],axis=1)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        \nfor c in test.columns:\n    if test[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(test[c].values)) \n        test[c] = lbl.transform(list(test[c].values))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape,test.shape)","execution_count":16,"outputs":[{"output_type":"stream","text":"(30470, 293) (7662, 293)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class two_estimator:\n    def __init__(self,owner_params,invest_params):\n        self.est1=xgb.XGBRegressor(**owner_params)\n        self.est2=xgb.XGBRegressor(**invest_params)\n        \n    def preprocess_owner(self,data,mode):\n         assert (data['product_type'].values==1).all()\n         if mode=='predict':\n            data.loc[data['full_sq'].isnull(),'full_sq'] = 50\n         return data\n    \n    def preprocess_invest(self,data,mode):\n         if mode=='predict':\n                assert (data['product_type'].values==0).all()\n                data.loc[data['full_sq'].isnull(),'full_sq'] = 50\n         return data\n    \n    def fit(self,X,y):\n        X1 = X[X['product_type']==1]\n        X2 = X\n        X1 = self.preprocess_owner(X1,'train')\n        y1 = y.loc[X1.index.values]/X1['full_sq']\n        X2 = self.preprocess_invest(X2,'train')\n        y2 = y\n        if len(X1)>0:\n            self.est1.fit(X1,y1)\n        if len(X2)>0:\n            self.est2.fit(X2,y2)\n    \n    def predict(self,X):\n        X1=X[X['product_type']==1]\n        X2=X[X['product_type']==0]\n        owner_index = X1.index.values\n        investment_index = X.index.drop(owner_index).values\n        X1 = self.preprocess_owner(X1,'predict')\n        X2 = self.preprocess_invest(X2,'predict')\n        res=pd.DataFrame(index=X.index)\n        if len(X1)>0:\n            pred1 = self.est1.predict(X1)\n            res.loc[owner_index,0] = pred1*X1['full_sq']\n        if len(X2)>0:\n            pred2 = self.est2.predict(X2)\n            res.loc[investment_index,0] = pred2    \n        return res[0].values.flatten()","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators=[]\no=0\nfor i in range(50):\n    owner_params = {\n            'n_estimators':200,\n            'eta':0.05,\n            'max_depth':6,\n            'min_child_weight':1,\n            'subsample':0.8,\n            'colsample_bytree':0.9,\n            'colsample_bylevel':1,\n            'reg_alpha':0,\n            'reg_lambda':1,\n            'seed':i,\n            'eval_metric':'rmse',\n            'objective':'reg:squarederror',\n            'nthread':8\n           }\n    invest_params = {\n            'n_estimators':200,\n            'eta':0.05,\n            'max_depth':6,\n            'min_child_weight':1,\n            'subsample':0.8,\n            'colsample_bytree':0.9,\n            'colsample_bylevel':1,\n            'reg_alpha':0,\n            'reg_lambda':1,\n            'seed':i,\n            'eval_metric':'rmse',\n            'objective':'reg:squarederror',\n            'nthread':8\n            }\n    est=two_estimator(owner_params,invest_params)\n    est.fit(train,Y)\n    estimators.append(est)\n    o=o+1\n    if o%10==0:\n        print(o)\n        ","execution_count":28,"outputs":[{"output_type":"stream","text":"10\n20\n30\n40\n50\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds=np.zeros(shape=test.values.shape[0])\ncnt=0\nfor e in estimators:\n    result=e.predict(test)\n    preds=preds+result\n    if cnt%10==0:\n        print(cnt)\n    cnt+=1\npreds/=len(estimators)\n","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'np' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-edb6dbaef56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile('../input/sberbank-russian-housing-market/sample_submission.csv.zip') as f:\n    f.extractall('.')","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=pd.read_csv('../working/sample_submission.csv')\npred1 = preds*0.96\nsample['price_doc']=pred1\nsample.to_csv('model2.csv',index=False)\nsample.head()","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"      id     price_doc\n0  30474  5.509215e+06\n1  30475  8.219325e+06\n2  30476  5.391261e+06\n3  30477  6.270258e+06\n4  30478  5.169080e+06","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price_doc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30474</td>\n      <td>5.509215e+06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30475</td>\n      <td>8.219325e+06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30476</td>\n      <td>5.391261e+06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30477</td>\n      <td>6.270258e+06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30478</td>\n      <td>5.169080e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}